---
title: "NewDistributionTest"
author: "Will MacKenzie"
date: "18/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(clhs)
library(sf)
library(raster)
library(sp)
library(gdistance)
library(foreach)
library(data.table)
library(fasterize)
library(reticulate)
library(here)
library(LearnGeom)
library(tidyverse)
library(goftest)
library(velox)
require(ggthemes)

```

The below chunk creates some generic statistical functions

```{r source}
source_python("./mTSP.py")

##Kolmogorov-Smirnov test
sumKSTest <- function(full,small){
  out <- 0
  for(i in 1:ncol(full)){
    ks <- suppressWarnings(ks.test(full[,i],small[,i]))
    out <- out+ks$statistic
  } 
  return(out)
}

sumKSTestTransect <- function(full,small){
  out <- 0
  for(i in 1:full$nbands){
    ks <- suppressWarnings(ks.test(full$rasterbands[[i]],small[,i]))
    out <- out+ks$statistic
  } 
  return(out)
}

# adTest <- function(full,small){
#   out <- 0
#   for(i in 1:ncol(full)){
#     fn <- ecdf(full[,i])
#     temp <- ad.test(small[,i], null = fn)
#     out <- out + temp$statistic
#   }
#   return(out)
# }

fillTest <- function(full, small){
  strata <- apply(
    full, 
    2, 
    function(x) {
      quantile(x, probs = seq(0, 1, 0.01), na.rm = TRUE)
    }
  )
  fillQual <- foreach(var = 1:ncol(full),.combine = cbind) %do% {
    .Call(graphics:::C_BinCount, small[,var], strata[,var], TRUE,TRUE)
  }
  
  return(length(fillQual[fillQual == 0])) 
}

fillTest_Transect <- function(full, small){
  strata <- lapply(
    full$rasterbands, 
    function(x) {
      quantile(x, probs = seq(0, 1, 0.01), na.rm = TRUE)
    }
  )
  fillQual <- foreach(var = 1:full$nbands,.combine = cbind) %do% {
    .Call(graphics:::C_BinCount, small[,var], strata[[var]], TRUE,TRUE)
  }
  
  return(length(fillQual[fillQual == 0])) 
}

x=0; y=0
Tri_build <- function(id, x, y){
  tris <- CreateRegularPolygon(3, c(x,y), 145) # number of sides, center pt and length of sides
  tris <- tris[c(1:3,1),]
  lines <- st_linestring(tris)
  
  g = st_sfc(lines)
  out <- st_sf(g,ID = id)
  #st_set_crs(newproj)
  return(out)
} 
```

Load data and setup covariates

```{r load data}
datLocGit <- here("InputData") ## Data
covLoc <- here("Covariates") ## Too big for git data

### landscape levels covariates
covars <- paste(covLoc, c("25m_DAH_3Class.tif","25m_LandformClass_Default_Seive4.tif",
                          "25m_MRVBF_Classified_IS64Low6Up2.tif","becRaster.tif"), sep = "/")# ,"DEM_25m.tif"
layerNamesLL <- c("DAH","LFC","MRVBF","BEC", "cost") ##need to change this if you change the layers
#becLayer <- raster(paste(covLoc,"becRaster.tif", sep = "/")) ## use these will apply to only a single BGC
#becLayer[becLayer != 3] <- NA
ancDatLL <- raster::stack(covars)
proj4string(ancDatLL) <- "+init=epsg:3005"
#ancDatLL <- mask(ancDatLL,becLayer)

LL_corr <- layerStats(ancDatLL, 'pearson', na.rm=T)
corr_matrixLL <- LL_corr$'pearson correlation coefficient'

## stand level covariates (about 11 million r)
SLcov <- c("twi.tif","valley_depth_2.tif","tca2.tif","swi_area_mod.tif","tpi.tif")
covars <- paste(covLoc, SLcov, sep = "/")
layerNamesSl <- c("twi","valley","tca2","swi","tpi") ##need to change this if you change the layers
ancDatSL <- raster::stack(covars)
proj4string(ancDatSL) <- "+init=epsg:3005"
#ancDatSL <- mask(ancDatSL, becLayer)

#ancDatLL_cost <- stack(ancDatLL,acost2)
fullSet <- sampleRegular(ancDatLL, size = 100000,sp = T) 
X <- st_as_sf(fullSet) ##This line takes a while, but I'm not sure of an alternative
X <- X[!is.na(X$X25m_DAH_3Class),]

# fullSet <- sampleRegular(ancDatLL_cost, size = 100000,sp = T)
# Xcost <- st_as_sf(fullSet)
# Xcost <- Xcost[!is.na(Xcost$X25m_DAH_3Class),]
# Xcost <- Xcost[!is.infinite(Xcost$layer),]

ancDatVL <- velox(ancDatSL) ##create velox object


##Turn into data.frame, bin each variable, combine into a label, scount by label
ancVals <- as.data.table(getValues(ancDatSL))
ancVals <- na.omit(ancVals)
ancBin <- ancVals[,lapply(.SD, function(x){cut(x,breaks = seq(min(x), max(x), length.out = 9),labels = F,include.lowest = T)})] ##put into 10 bins by quantile
ancBin <- unite(ancBin, LHSVar, sep = "")
ancBin[,LHSVar := as.numeric(LHSVar)]
ancBin <- ancBin[,.(Num = .N), by = .(LHSVar)] ##count occurences
ancSmall <- ancBin[Num > 99,] ##remove uncommon
setorder(ancSmall,-Num)
#plot(ancSmall$Num, type = "l")
ancQuants <- ancVals[,lapply(.SD,function(x){seq(min(x), max(x), length.out = 9)})] ##save quantiles of full set

##now testing a sampled set - temp should be the result of one of the sample functions (e.g. createCCLHS)

##regular single point clhs
# temp <- clhs(ancVals,size = 600, use.cpp = T, simple = F)
# temp <- temp$sampled_data

## Transects regular resample
# n = 40
# xMat <- st_drop_geometry(Xcost)
# temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T,simple = F)
# dat <- X[temp$index_samples,]
# small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
#   tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
#   tPs <- st_sample(tri, size = 15, type = "regular")
#   temp <- suppressWarnings(st_sf(data.frame(id = j, geometry = tPs)) %>%
#      st_cast("POINT"))
#   temp
#   
# }
# small <- st_as_sf(small)
# temp <- ancDat$extract_points(small)
# temp <- temp[!is.na(temp[1,]),]

##all transects
n = 40
xMat <- st_drop_geometry(Xcost)
temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T,simple = F)
dat <- X[temp$index_samples,]
small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
  tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
  tempDat <- ancDat$extract(tri)
  tempDat <- tempDat[[1]]
  tempDat
}
temp <- small[complete.cases(small),]

sampDat <- as.data.table(temp)
##split into same bins as full data set
for(i in 1:ncol(sampDat)){
  sampDat[[i]] <- cut(sampDat[[i]],breaks = ancQuants[[i]], labels = F, include.lowest = T)
}
sampBin <- unite(sampDat,sampLHS,sep = "")
sampBin[,sampLHS := as.numeric(sampLHS)]
sampBin <- sampBin[,.(SampNum = .N), by = .(sampLHS)]##count
##merge to compare
fullDat <- ancSmall
fullDat[sampBin, SampNum := i.SampNum, on = c(LHSVar = "sampLHS")]
fullDat[is.na(SampNum), SampNum := 0]
fullDat[,SampNum := SampNum/sum(SampNum)]
fullDat[,Num := Num/sum(Num)]
fullDat[,LHSID := seq_along(Num)]
ks_stat(fullDat$Num,fullDat$SampNum)

fullDat <- melt(fullDat, id.vars = c("LHSID","LHSVar"))
ggplot(fullDat, aes(x = LHSID, y = value, col = variable))+
  geom_line()

ks_stat <- function(yFull,ySample){
  cumFull <- cumsum(yFull)
  cumSamp <- cumsum(ySample)
  diff <- abs(cumFull - cumSamp)
  return(max(diff))
}
#################
###output selected bins to new spatial layer for review
## select non-bin values to NA
ancDatSL.temp <- ancDatSL
ancDatSL.temp$twi[ancDatSL.temp$twi < 4.71] <- NA
ancDatSL.temp$twi[ancDatSL.temp$twi > 7.16] <- NA
ancDatSL.temp$valley_depth_2[ancDatSL.temp$valley_depth_2  > 60.44] <- NA
ancDatSL.temp$tca2[ancDatSL.temp$tca2  > 625] <- NA
ancDatSL.temp$swi_area_mod[ancDatSL.temp$swi_area_mod > 625] <- NA

### calculate a new layer from a sum of covariates including NA will set any where an NA exists to NA
newlayer <- raster::calc(ancDatSL.temp, sum, na.rm=F)
writeRaster(ancDatSL.temp$twi, "./Tests/SelectedCovariateBins.tif", format = "GTiff", overwrite  = TRUE)
writeRaster(newlayer, "./Tests/AllSLCovariateBins.tif", format = "GTiff", overwrite  = TRUE)
```
