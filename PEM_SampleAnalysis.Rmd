---
title: "PEM Sample Analysis"
author: "Kiri Daust"
date: "20/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(clhs)
library(sf)
library(raster)
library(sp)
library(gdistance)
library(foreach)
library(data.table)
library(fasterize)
library(reticulate)
library(here)
library(LearnGeom)
library(tidyverse)
library(goftest)
library(velox)
require(ggthemes)

```

The below chunk creates some generic statistical functions

```{r source}
source_python("./mTSP.py")

##Kolmogorov-Smirnov test
sumKSTest <- function(full,small){
  out <- 0
  for(i in 1:ncol(full)){
    ks <- suppressWarnings(ks.test(full[,i],small[,i]))
    out <- out+ks$statistic
  } 
  return(out)
}

sumKSTestTransect <- function(full,small){
  out <- 0
  for(i in 1:full$nbands){
    ks <- suppressWarnings(ks.test(full$rasterbands[[i]],small[,i]))
    out <- out+ks$statistic
  } 
  return(out)
}

adTest <- function(full,small){
  out <- 0
  for(i in 1:ncol(full)){
    fn <- ecdf(full[,i])
    temp <- ad.test(small[,i], null = fn)
    out <- out + temp$statistic
  }
  return(out)
}

fillTest <- function(full, small){
  strata <- apply(
    full, 
    2, 
    function(x) {
      quantile(x, probs = seq(0, 1, 0.01), na.rm = TRUE)
    }
  )
  fillQual <- foreach(var = 1:ncol(full),.combine = cbind) %do% {
    .Call(graphics:::C_BinCount, small[,var], strata[,var], TRUE,TRUE)
  }
  
  return(length(fillQual[fillQual == 0])) 
}

Tri_build <- function(id, x, y){
  tris <- CreateRegularPolygon(3, c(as.numeric(paste(x)), 
                                    as.numeric(paste(y))), 145) # number of sides, center pt and length of sides
  
  MoonLineCentre <- data.frame(tris) %>%
    st_as_sf(., coords = c("X", "Y"), crs = 3005) %>%
    mutate(id = id) %>%
    group_by(id) %>%
    dplyr::summarise() %>%
    st_cast("POLYGON") %>%
    st_cast("MULTILINESTRING") #%>%
  #st_set_crs(newproj)
  return(MoonLineCentre)
} 
```

Load data and setup covariates

```{r load data}
datLocGit <- here("InputData") ## Data
covLoc <- here("Covariates") ## Too big for git data

### landscape levels covariates
covars <- paste(covLoc, c("25m_DAH_3Class.tif","25m_LandformClass_Default_Seive4.tif",
                          "25m_MRVBF_Classified_IS64Low6Up2.tif","dem.tif","becRaster.tif"), sep = "/")# ,"DEM_25m.tif"
layerNamesLL <- c("DAH","LFC","MRVBF","DEM","BEC", "cost") ##need to change this if you change the layers
ancDatLL <- raster::stack(covars)
proj4string(ancDatLL) <- "+init=epsg:3005"

LL_corr <- layerStats(ancDatLL, 'pearson', na.rm=T)
corr_matrixLL <- LL_corr$'pearson correlation coefficient'

## stand level covariates
SLcov <- c("twi.tif","valley_depth_2.tif","tca2.tif","swi_area_mod.tif","cov.tif","tpi.tif")
covars <- paste(covLoc, SLcov, sep = "/")
layerNamesSl <- c("twi","valley","tca2","swi","cov","tpi") ##need to change this if you change the layers
ancDatSL <- raster::stack(covars)
proj4string(ancDatSL) <- "+init=epsg:3005"

SL_corr <- layerStats(ancDatSL, 'pearson', na.rm=T)
corr_matrixSL <- SL_corr$'pearson correlation coefficient'

##combine layers to compare correlation
ancDatLL2 <- projectRaster(ancDatLL, ancDatSL, method = 'ngb')
ancDatALL <- stack(ancDatSL, ancDatLL2)
All_corr <- layerStats(ancDatALL, 'pearson', na.rm=T)
corr_matrixAll <- All_corr$'pearson correlation coefficient'

## dem for transtion layer
alt <- raster(paste0(covLoc, "/dem.tif"))
proj4string(alt) <- "+init=epsg:3005"

## template raster
allRast <- raster(paste0(covLoc,"/Road_Rast_Small.tif"))    
allRast[allRast == 255] <- NA
allRast <- trim(allRast)

###read in roads
rdsAll <- st_read(paste0(datLocGit,"/road_access_for_cost.gpkg"))
rdsAll <- rdsAll[,"DESCRIPTIO"]
colnames(rdsAll)[1] <- "road_surface"
rdsAll <- as.data.table(rdsAll) %>% st_as_sf()

##Smithers start location
start_sf <- st_read("SmithersStart.gpkg")
start <- as(start_sf, "Spatial")
```

This section creates the transition layer from the slope and clost surface using Tobler's hiking function

```{r create cost surface}
##road speed
rSpd <- fread("road_speed.csv")
rSpd[,Values := speed]
rdsAll <- merge(rdsAll, rSpd, by = "road_surface", all = F)
rdsAll <- rdsAll[,"Values"] %>%
  st_buffer(dist = 35, endCapStyle = "SQUARE", joinStyle = "MITRE") %>%
  st_cast("MULTIPOLYGON")
rdsRast <- fasterize(rdsAll, allRast, field = "Values")

alt2 <- projectRaster(alt,rdsRast,method = 'ngb')
altAll <- merge(rdsRast, alt2)

## trasition function: if > 500, elevation, so get diff, else speed to select min
trFn <- function(x){
  if(x[1] > 500 & x[2] > 500){
    x[1]-x[2]
  }else{
    min(x[1],x[2])
  }
}

rdIdx <- which(values(altAll) < 100) ##which cells are for roads?
slpIdx <- which(values(altAll) > 500)
adj <- adjacent(altAll, cells = slpIdx, pairs = T, directions = 8)
adj <- adj[!adj[,1] %in% rdIdx ,] ##remove roads inside area
adj <- adj[!adj[,2] %in% rdIdx ,]

tr <- transition(altAll,trFn,directions = 8, symm = F) ##altDiff and speed (km/h)
tr1 <- geoCorrection(tr) ##divided by 25 - slope and conductance (km/h/m)
tr1[adj] <- (3/5)*(6*exp(-3.5*abs(tr1[adj] + 0.08))) ##tobler's hiking function * 3/5 - gives km/h
tr1 <- tr1*1000 ##now roads are correct conductance (h/m), and walking in m/h
tr2 <- geoCorrection(tr1) ##have to geocorrect this part again
tr1[adj] <- tr2[adj] ##tr1 values are now all conductance in h/metre

acost <- accCost(tr1,start)
plot(acost)

acost2 <- projectRaster(acost, ancDatSL)
acost2 <- mask(acost2, alt)
ancDatSL_cost <- stack(ancDatSL,acost2)
```
### Simulation 1: Single point sampling

For all the following simulations we're testing with random samples, LHS samples, CCLHS samples and sometimes TSP sampling (not for single points).

There are different ways of testing space filling: in the below code, we use KS statistics, a simple bin fill function, and the AD test (doesn't seem to work well)

```{r single point}
fullSet <- sampleRegular(ancDatSL, size = 10000,useGDAL = T)
X <- fullSet
X <- X[complete.cases(X),]

fullSet <- sampleRegular(ancDatSL_cost, size = 10000,useGDAL = T)
Xcost <- fullSet
Xcost <- Xcost[complete.cases(Xcost),]

##functions to create sampling setups
createRandom <- function(X,n){
  small <- sample(1:nrow(X),size = n, replace = F)
  return(X[small,])
}

createLHS <- function(X,n){
  temp <- clhs(X,size = n, cost = NULL, use.cpp = T, iter = 5000, simple = F)
  small <- as.matrix(temp$sampled_data)
  return(small)
}
createCCLHS <- function(X,n){
  temp <- clhs(X,size = n,cost = ncol(X),use.cpp = T, iter = 1000,simple = F)
  small <- as.matrix(temp$sampled_data)
  return(small)
}

require(doParallel)
cl <- makePSOCKcluster(detectCores()-2)
registerDoParallel(cl)

##collecting stats with different space filling tests
collectStats <- function(X,sampleFun,nums,testFun1 = sumKSTest,testFun2 = fillTest){
  test_res <- foreach(n = nums, .combine = rbind, 
                    .packages = c("Rcpp","LaplacesDemon","foreach","goftest","clhs")) %dopar% {
                      smallSet <- sampleFun(as.data.frame(X),n)
                      res1 <- testFun1(X[,1:6],smallSet)
                      res2 <- testFun2(X[,1:6], smallSet)
                      #res3 <- testFun3(X[,1:6], smallSet)
                      data.frame(Num = n,KS = res1, fill = res2)
                    }
  return(test_res)
}

nums <- round(seq(10, 800, length.out = 10))
nums <- rep(nums, each = 5)
statsRand <- collectStats(X,createRandom,nums)
statsRand$SType <- "Random"
statsLHS <- collectStats(X,createLHS, nums)
statsLHS$SType <- "LHS"
statsCCLHS <- collectStats(Xcost,createCCLHS, nums)
statsCCLHS$SType <- "CCLHS"

statsAll <- rbind(statsRand,statsLHS,statsCCLHS)
statsAll$Num <- as.factor(statsAll$Num)
statsAll$SType <- as.factor(statsAll$SType)

# ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
#   geom_boxplot()
# ggplot(statsAll, aes(x = Num, y = fill, fill = SType))+
#   geom_boxplot()

statsAll <- as.data.table(statsAll)
statsAll[, Norm := (KS-min(KS))/(max(KS)-min(KS))]
statsAll[,Norm := 1-Norm]
KSplot <- ggplot(statsAll, aes(x = Num, y = Norm, fill = SType))+
  geom_boxplot() +
  labs(x = "Minimum Number of Training Points", y= "Kolmogorov-Smirnov statistic")+ 
  scale_fill_discrete(guide = guide_legend(reverse=TRUE), name='Sample Method', labels = c('cost cLHS', 'cLHS', 'random'))+
  theme_few()
plot(KSplot)
ggsave("./Results/K-S Plot.jpeg", device = 'jpeg')

binfillplot <- ggplot(statsAll, aes(x = Num, y = fill, fill = SType))+
  geom_boxplot() +
  labs(x = "Minimum Number of Training Points", y= "Bins remaining to be filled")+ 
  scale_fill_discrete(guide = guide_legend(reverse=TRUE), name='Sample Method', labels = c('cost cLHS', 'cLHS', 'random'))+
  theme_few()
plot(binfillplot)
ggsave("./Results/Bin fill Plot.jpeg", device = 'jpeg')


```

### Simulation 2: Transect Sampling

Now instead of choosing single points, we use the cclhs or lhs to pick centre points, and then create a triangular transect around it, which we then sample from (either using a second clhs or just regular spacing). The below chunk simulates 3 transect scenarios: non cost-constrained clhs, using clhs to sample from transects, and cost-constrained clhs using both clhs and regular spacing for transect sampling. Note that this chunk takes a while to run and will use all your CPU resources. The time limiting part is not the clhs function, but rather extracting data from the raster stack once each transect has been created (even using Velox this takes a while).

```{r set up transect simulations}
ancDatLL_cost <- stack(ancDatLL,acost2)
fullSet <- sampleRegular(ancDatLL, size = 100000,sp = T) 
X <- st_as_sf(fullSet) ##This line takes a while, but I'm not sure of an alternative
X <- X[!is.na(X$X25m_DAH_3Class),]
# 
 fullSL <- sampleRegular(ancDatSL, size = 100000,GDAL = T)
 fullSL <- fullSL[complete.cases(fullSL),]

fullSet <- sampleRegular(ancDatLL_cost, size = 100000,sp = T)
Xcost <- st_as_sf(fullSet)
Xcost <- Xcost[!is.na(Xcost$X25m_DAH_3Class),]
Xcost <- Xcost[!is.infinite(Xcost$layer),]

ancDatVL <- velox(ancDatSL) ##create velox object

###create LHS transect sample, use clhs to sample transects
createLHS <- function(X,n,ancDat){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = NULL,iter = 5000,use.cpp = T,simple = F)
  dat <- X[temp$index_samples,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tempDat <- ancDat$extract(tri)
    tempDat <- tempDat[[1]]
    tempDat
  }
  small <- small[complete.cases(small),]
  sl_lhs <- clhs(as.data.frame(small), size = 25*n, iter = 5000,use.cpp = T,simple = F)
  temp <- sl_lhs$sampled_data
  return(temp)
}

##create cclhs sample, extract points @ 30m intervals
createCCLHS_30m <- function(X,n,ancDat){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T,simple = F)
  dat <- X[temp$index_samples,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tPs <- st_sample(tri, size = 25, type = "regular")
    temp <- suppressWarnings(st_sf(data.frame(id = j, geometry = tPs)) %>%
       st_cast("POINT"))
    temp
    
  }
  temp <- suppressWarnings(raster::extract(ancDat, small))
  temp <- temp[!is.na(temp[1,]),]
  return(temp)
}

##create cclhs transects, sample using lhs
createCCLHS <- function(X,n,ancDat){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T,simple = F)
  dat <- X[temp$index_samples,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tempDat <- ancDat$extract(tri)
    tempDat <- tempDat[[1]]
    tempDat
  }
  small <- small[complete.cases(small),]
  sl_lhs <- clhs(as.data.frame(small), size = 25*n, iter = 5000,use.cpp = T,simple = F)
  temp <- sl_lhs$sampled_data
  return(temp)
}

##function to run simulations
collectStats <- function(X,sampleFun,nums,testFun1 = sumKSTestTransect,testFun2 = fillTest,ancDat){
  pkgs <- c("Rcpp","LaplacesDemon", "foreach","sf",
          "raster","LearnGeom","dplyr","reticulate","gdistance","scales","velox","clhs")
  test_res <- foreach(n = nums, .combine = rbind, .packages = pkgs,
                    .export = c("Tri_build","fullSL","start_sf","tr1")) %dopar% { #
                      reticulate::source_python("mTSP.py")
                      smallSet <- sampleFun(X,n,ancDat)
                      smallSet <- smallSet[complete.cases(smallSet),]
                      if(nrow(smallSet) > 1){
                        res1 <- testFun1(ancDat,smallSet)
                        res2 <- testFun2(fullSL,smallSet)
                        data.frame(Num = n,KS = res1, fillQual = res2)
                      }else{
                        NULL
                      }
                      
                    }
  return(test_res)
}
```

```{r run simulations}
nums <- round(seq(5, 10, length.out = 10)) ##set sequence of transect number
nums <- rep(nums, each = 2) ##replicates of each number (should be at least 5)
statsLHS_trans <- collectStats(X,createLHS,nums,ancDat = ancDatVL)
statsLHS_trans$SType = "LHS"
#fwrite(statsLHS_trans, "LHSNumSave.csv")
statsCCLHS_trans <- collectStats(Xcost,createCCLHS,nums, ancDat = ancDatVL)
statsCCLHS_trans$SType <- "CCLHS"
#fwrite(statsCCLHS_trans, "CCLHSNumSave.csv")

statsCCLHS_30m <- collectStats(Xcost, createCCLHS_30m, nums, ancDat = ancDatVL)
statsCCLHS_30m$SType <- "CCLHSReg"

##plot
statsAll <- rbind(statsLHS_trans,statsCCLHS_trans,statsCCLHS_30m)
statsAll$Num <- as.factor(statsAll$Num)
statsAll$SType <- as.factor(statsAll$SType)
ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
  geom_boxplot()
ggplot(statsAll, aes(x = Num, y = fillQual, fill = SType))+
  geom_boxplot()

KS_transectPlot <- ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
  geom_boxplot() +
  labs(x = "Number of Transects", y= "Kolmogorov-Smirnov statistic (0 = identical)")+
  scale_fill_discrete(guide = guide_legend(reverse=FALSE), name='Sample Method', labels = c('cLHS- cLHS resampled', 'cost cLHS - cLHS resampled', 'cost cLHS systematic resampled'))+
  theme_few()
plot(KS_transectPlot)
ggsave("./Results/KS_transect_plot.jpeg", device = 'jpeg')

Bfill_transectPlot <- ggplot(statsAll, aes(x = Num, y = fillQual, fill = SType))+
  geom_boxplot() +
  labs(x = "Number of Transects", y= "Bins remaining to be filled")+
  scale_fill_discrete(guide = guide_legend(reverse=FALSE), name='Sample Method', labels = c('cLHS- cLHS resampled', 'cost cLHS - cLHS resampled', 'cost cLHS systematic resampled'))+
  theme_few()
plot(Bfill_transectPlot)
ggsave("./Results/KS_transectPlot.jpeg", device = 'jpeg')

```

This next chunk is basically the same as above but using the TSP and allowing drops. I separated it because this part takes longer, so might not want to always run it.

```{r}
##function to make TSP
createTSP <- function(X,n,ancDat){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T, simple = F)
  dat <- X[temp$index_samples,]

  pnts <- dat
  
  p2 <- st_as_sf(pnts)
  pnts <- pnts[,1]
  colnames(pnts) <- c("name","geometry")
  st_geometry(pnts) <- "geometry"
  startPnts <- st_as_sf(data.frame(name = "Start",geometry = start_sf))
  pnts <- rbind(pnts, startPnts)
  pnts2 <- as(pnts, "Spatial")
  
  ## create distance matrix between sample points
  test <- costDistance(tr1,pnts2,pnts2)
  dMat2 <- as.matrix(test)
  dMat2 <- dMat2*60
  dMat2[is.infinite(dMat2)] <- 1000
  
  ##penalty based on quality of points
  objVals <- temp$final_obj_continuous
  objVals <- max(objVals) - objVals
  
  maxTime <- 8L ##hours
  ## time per transect
  plotTime <- 45L ##mins
  temp <- dMat2[1:n,1:n]
  maxDist <- sum(temp[upper.tri(temp)])
  minPen <- maxDist * 1.5
  maxPen <- maxDist * 5
  objVals <- scales::rescale(objVals, to = c(minPen,maxPen))
  objVals <- as.integer(objVals)
  
  ndays <- as.integer(ceiling(n/5)+1)
  indStart <- as.integer(rep(n,ndays))
  ##run vehicle routing problem from python script
  ## GCS is global span cost coefficient
  vrp <- py_mTSP(dat = dMat2,num_days = ndays, start = indStart, end = indStart, 
                 max_cost = maxTime*60L, plot_time = plotTime, penalty =  objVals, arbDepot = F, GSC = 15L)
  
  result <- vrp[[1]]
  idxs <- as.numeric(unlist(result))
  idxs <- idxs[idxs != n]
  idxs <- idxs+1
  
  dat <- pnts[idxs,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tempDat <- ancDat$extract(tri)
    tempDat <- tempDat[[1]]
    tempDat
  }
  small <- small[complete.cases(small),]
  sl_lhs <- clhs(as.data.frame(small), size = 25*n, iter = 5000,use.cpp = T, simple = F)
  temp <- sl_lhs$sampled_data
  return(temp)
}

##run simulations
pkgs <- c("Rcpp","LaplacesDemon", "foreach","sf",
          "raster","LearnGeom","dplyr","reticulate","gdistance","scales","velox","clhs")
statsTSP_trans <- foreach(n = nums, .combine = rbind, .packages = pkgs,
                    .export = c("Tri_build","fullSL","start_sf","tr1")) %dopar% { #
                      reticulate::source_python("mTSP.py")
                      smallSet <- createTSP(Xcost,n,ancDatVL)
                      smallSet <- smallSet[complete.cases(smallSet),]
                      if(nrow(smallSet) > 1){
                        res1 <- sumKSTest(fullSL,smallSet)
                        res2 <- fillTest(fullSL,smallSet)
                        data.frame(Num = n,KS = res1, fillQual = res2)
                      }else{
                        NULL
                      }
                      
                }

statsTSP_trans$SType <- "TSP"
#fwrite(statsTSP_trans, "TSPNumSave.csv")

##combine with above chunk
statsAll <- rbind(statsLHS_trans,statsCCLHS_trans,statsCCLHS_30m,statsTSP_trans)
statsAll$Num <- as.factor(statsAll$Num)
statsAll$SType <- as.factor(statsAll$SType)
ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
  geom_boxplot()
ggplot(statsAll, aes(x = Num, y = fillQual, fill = SType))+
  geom_boxplot()

KS_transectPlot2 <- ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
  geom_boxplot() +
  labs(x = "Number of Transects", y= "Kolmogorov-Smirnov statistic (0 = identical)")+
  scale_fill_discrete(guide = guide_legend(reverse=FALSE), name='Sample Method', labels = c('cLHS- cLHS resampled', 'cost cLHS - cLHS resampled', 'cost cLHS systematic resampled'))+
  theme_few()
plot(KS_transectPlot2)
ggsave("./Results/KS_transect_plot2.jpeg", device = 'jpeg')

Bfill_transectPlot2 <- ggplot(statsAll, aes(x = Num, y = fillQual, fill = SType))+
  geom_boxplot() +
  labs(x = "Number of Transects", y= "Bins remaining to be filled")+
  scale_fill_discrete(guide = guide_legend(reverse=FALSE), name='Sample Method', labels = c('cLHS- cLHS resampled', 'cost cLHS - cLHS resampled', 'cost cLHS systematic resampled'))+
  theme_few()
plot(Bfill_transectPlot2)
ggsave("./Results/KS_transectPlot2.jpeg", device = 'jpeg')
```

## Simulation 3: Sampling Time

The previous chunks investigated how variable space filling changed with different sampling strategies. We now apply the same process, but collect results on the amount of time each plan would take (as determined by the TSP). We use similar sampling plans as in the above chunks: cost-constrained clhs, regular clhs, and TSP (same as cost-constrained clhs, but allowing dropped sites). As above, the simulation runs each scenario with increasing numbers of transects and multiple replications at each level.

```{r time cost}

##create TSP to calculate time
calcCost <- function(pnts,objVals,dropAllowed){
  n = nrow(pnts)
  p2 <- st_as_sf(pnts)
  pnts <- pnts[,1]
  colnames(pnts) <- c("name","geometry")
  st_geometry(pnts) <- "geometry"
  startPnts <- st_as_sf(data.frame(name = "Start",geometry = start_sf))
  pnts <- rbind(pnts, startPnts)
  pnts2 <- as(pnts, "Spatial")
  
  ## create distance matrix between sample points
  test <- costDistance(tr1,pnts2,pnts2)
  dMat2 <- as.matrix(test)
  dMat2 <- dMat2*60
  dMat2[is.infinite(dMat2)] <- 1000
  
  ##penalty based on quality of points
  objVals <- max(objVals) - objVals
  
  maxTime <- 8L ##hours
  ## time per transect
  plotTime <- 45L ##mins
  temp <- dMat2[1:n,1:n]
  maxDist <- sum(temp[upper.tri(temp)])
  minPen <- maxDist
  maxPen <- maxDist * 4
  objVals <- scales::rescale(objVals, to = c(minPen,maxPen))
  objVals <- as.integer(objVals)
  
  if(dropAllowed){
    ndays <- as.integer(ceiling(n/5)+1)
    pen = objVals
  }else{
    ndays <- as.integer(ceiling(n/2))
    pen = as.integer(objVals*10)
  }
  
  indStart <- as.integer(rep(n,ndays))
  ##run vehicle routing problem from python script
  ## GCS is global span cost coefficient
  vrp <- py_mTSP(dat = dMat2,num_days = ndays, start = indStart, end = indStart, 
                 max_cost = maxTime*60L, plot_time = plotTime, penalty =  pen, arbDepot = F, GSC = 5L)
  time <- vrp[[2]]
  totTime <- sum(as.numeric(unlist(time)))
  return(totTime)
}

## regular clhs
timeLHS <- function(X,n){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = NULL,iter = 5000,use.cpp = T,simple = F)
  return(temp)
}

## cost_constrained clhs
timeCCLHS <- function(X,n){
  xMat <- st_drop_geometry(X)
  temp <- clhs(xMat,size = n,cost = ncol(xMat),iter = 5000,use.cpp = T,simple = F)
  return(temp)
}

##function to run simulations
collectTime <- function(X,sampleFun, num, dropAllowed){
  pkgs <- c("Rcpp","LaplacesDemon", "foreach","sf",
          "raster","LearnGeom","dplyr","reticulate","gdistance","scales","clhs")
  test_res <- foreach(n = num, .combine = rbind, .packages = pkgs,
                    .export = c("start_sf","tr1", "calcCost")) %dopar% { #
                      reticulate::source_python("mTSP.py")
                      templhs <- sampleFun(X,n)
                      dat <- X[templhs$index_samples,]
                      if(nrow(dat) > 1){
                        time <- calcCost(dat,templhs$final_obj_continuous,dropAllowed)
                        data.frame(Num = n, Cost = time)
                      }else{
                        NULL
                      }
                      
                    }
  return(test_res)
}

trans <- seq(5,60,by = 5) ##numbers of transects
trans <- rep(trans,each = 5) ##replications at each level

LHSTime <- collectTime(X,timeLHS,num = trans, dropAllowed = F)
LHSTime$Type = "LHS"
CCLHSTime <- collectTime(Xcost,timeCCLHS,num = trans, dropAllowed = F)
CCLHSTime$Type = "CCLHS"
TSPTime <- collectTime(Xcost, timeCCLHS, num = trans, dropAllowed = T)
TSPTime$Type = "TSP"

timeAll <- rbind(LHSTime,CCLHSTime,TSPTime)
timeAll$Cost <- timeAll$Cost/480 ##covert from minutes to 8-hour days

timeAll$Num <- as.factor(timeAll$Num)
timeAll$Type <- as.factor(timeAll$Type)

ggplot(timeAll, aes(x = Num, y = Cost, fill = Type))+
  geom_boxplot()

Time_plot <- ggplot(timeAll, aes(x = Num, y = Cost, fill = Type)) +
  geom_boxplot() +
  labs(x = "Number of Transects", y = "Time Cost to Sample Sufficient Samples") +
  scale_fill_discrete(
    guide = guide_legend(reverse = FALSE),
    name = 'Sample Method',
    labels = c(
      'cLHS- cLHS resampled',
      'cost cLHS - cLHS resampled',
      'cost cLHS systematic resampled'
    )
  ) +
  theme_few()
plot(Bfill_transectPlot2)
ggsave("./Results/KS_transectPlot2.jpeg", device = 'jpeg')

```

## Num Transects Needed

Another possibility for investigating sampling cost is running the code above, but instead of using increasing numbers of transects, fixing the number at the 90% variable space filling as determine by the previous simulations. The function below uses the simulation data from the above chunks (statsAll) and returns the estimated number of transects needed to reach 90% space filling. Note that the function will be inaccurate if you only simulated small numbers of transects.

```{r num}
numDat <- data.table(statsAll)

calcNumTrans <- function(type, numDat){
  tempDat <- numDat[SType == type,]
  temp <- tempDat[,.(y = median(KS)), by = .(Num)]
  temp[,`:=`(y = (y-min(y))/(max(y)-min(y)), Num = as.numeric(as.character(Num)))]
  l1 <- loess(Num ~ y, data = temp)
  
  temp <- tempDat[,.(y = median(fillQual)), by = .(Num)]
  temp[,`:=`(y = (y-min(y))/(max(y)-min(y)), Num = as.numeric(as.character(Num)))]
  l2 <- loess(Num ~ y, data = temp)
  numTrans <- predict(l1,data.frame(y = 0.15)) %>% 
    round(digits = 0) %>% as.integer()
  return(numTrans)
}

```

## Compare SS transect data to covariate space with DataExplorer
```{r}
SL <- fread("./InputData/Deception_Transect_SSxcovar_5m.csv")
LL <- fread("./InputData/Deception_Transect_SSxcovar_LL.csv")
LL <- LL %>% dplyr::select(mapunit1, mapunit2, '25m_MRVBF_', '25m_Landfo', '25m_DAH_3C')

DataExplorer::create_report(LL, y = "mapunit1")
```


