---
title: "PEM Sample Analysis"
author: "Kiri Daust"
date: "20/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(clhs)
library(sf)
library(raster)
library(sp)
library(gdistance)
library(foreach)
library(data.table)
library(fasterize)
library(reticulate)
library(here)
library(LearnGeom)
library(tidyverse)
library(goftest)
```

```{r source}
source("FastCLHS_R.R")
source_python("./mTSP.py")

##Kolmogorov-Smirnov test
sumKSTest <- function(full,small){
  out <- 0
  for(i in 1:ncol(full)){
    ks <- suppressWarnings(ks.test(full[,i],small[,i]))
    out <- out+ks$statistic
  } 
  return(out)
}

adTest <- function(full,small){
  out <- 0
  for(i in 1:ncol(full)){
    fn <- ecdf(full[,i])
    temp <- ad.test(small[,i], null = fn)
    out <- out + temp$statistic
  }
  return(out)
}

fillTest <- function(full, small){
  strata <- apply(
    full, 
    2, 
    function(x) {
      quantile(x, probs = seq(0, 1, 0.01), na.rm = TRUE)
    }
  )
  fillQual <- foreach(var = 1:ncol(full),.combine = cbind) %do% {
    .Call(graphics:::C_BinCount, small[,var], strata[,var], TRUE,TRUE)
  }
  
  return(length(fillQual[fillQual == 0])) 
}

Tri_build <- function(id, x, y){
  tris <- CreateRegularPolygon(3, c(as.numeric(paste(x)), 
                                    as.numeric(paste(y))), 145) # number of sides, center pt and length of sides
  
  MoonLineCentre <- data.frame(tris) %>%
    st_as_sf(., coords = c("X", "Y"), crs = 3005) %>%
    mutate(id = id) %>%
    group_by(id) %>%
    dplyr::summarise() %>%
    st_cast("POLYGON") %>%
    st_cast("MULTILINESTRING") #%>%
  #st_set_crs(newproj)
  return(MoonLineCentre)
} 
```

```{r load data}
datLocGit <- here("InputData") ## Data
covLoc <- here("Covariates") ## Too big for git data

### landscape levels covariates
covars <- paste(covLoc, c("25m_DAH_3Class.tif","25m_LandformClass_Default_Seive4.tif",
                          "25m_MRVBF_Classified_IS64Low6Up2.tif","dem.tif"), sep = "/")# ,"DEM_25m.tif"
layerNamesLL <- c("DAH","LFC","MRVBF","DEM","cost") ##need to change this if you change the layers
ancDatLL <- raster::stack(covars)
proj4string(ancDatLL) <- "+init=epsg:3005"

## stand level covariates
SLcov <- c("twi.tif","valley_depth_2.tif","tca2.tif","swi_area_mod.tif","cov.tif","tpi.tif")
covars <- paste(covLoc, SLcov, sep = "/")
layerNamesSl <- c("twi","valley","tca2","swi","cov","tpi") ##need to change this if you change the layers
ancDatSL <- raster::stack(covars)
proj4string(ancDatSL) <- "+init=epsg:3005"

## dem for transtion layer
alt <- raster(paste0(covLoc, "/dem.tif"))
proj4string(alt) <- "+init=epsg:3005"

## template raster
allRast <- raster(paste0(covLoc,"/Road_Rast_Small.tif"))    
allRast[allRast == 255] <- NA
allRast <- trim(allRast)

###read in roads
rdsAll <- st_read(paste0(datLocGit,"/road_access_for_cost.gpkg"))
rdsAll <- rdsAll[,"DESCRIPTIO"]
colnames(rdsAll)[1] <- "road_surface"
rdsAll <- as.data.table(rdsAll) %>% st_as_sf()

##Smithers start location
start_sf <- st_read("SmithersStart.gpkg")
start <- as(start_sf, "Spatial")
```

```{r create cost surface}
##road speed
rSpd <- fread("road_speed.csv")
rSpd[,Values := speed]
rdsAll <- merge(rdsAll, rSpd, by = "road_surface", all = F)
rdsAll <- rdsAll[,"Values"] %>%
  st_buffer(dist = 35, endCapStyle = "SQUARE", joinStyle = "MITRE") %>%
  st_cast("MULTIPOLYGON")
rdsRast <- fasterize(rdsAll, allRast, field = "Values")

alt2 <- projectRaster(alt,rdsRast,method = 'ngb')
altAll <- merge(rdsRast, alt2)

## trasition function: if > 500, elevation, so get diff, else speed to select min
trFn <- function(x){
  if(x[1] > 500 & x[2] > 500){
    x[1]-x[2]
  }else{
    min(x[1],x[2])
  }
}

rdIdx <- which(values(altAll) < 100) ##which cells are for roads?
slpIdx <- which(values(altAll) > 500)
adj <- adjacent(altAll, cells = slpIdx, pairs = T, directions = 8)
adj <- adj[!adj[,1] %in% rdIdx ,] ##remove roads inside area
adj <- adj[!adj[,2] %in% rdIdx ,]

tr <- transition(altAll,trFn,directions = 8, symm = F) ##altDiff and speed (km/h)
tr1 <- geoCorrection(tr) ##divided by 25 - slope and conductance (km/h/m)
tr1[adj] <- (3/5)*(6*exp(-3.5*abs(tr1[adj] + 0.08))) ##tobler's hiking function * 3/5 - gives km/h
tr1 <- tr1*1000 ##now roads are correct conductance (h/m), and walking in m/h
tr2 <- geoCorrection(tr1) ##have to geocorrect this part again
tr1[adj] <- tr2[adj] ##tr1 values are now all conductance in h/metre

acost <- accCost(tr1,start)
plot(acost)

acost2 <- projectRaster(acost, ancDatSL)
acost2 <- mask(acost2, alt)
ancDatSL_cost <- stack(ancDatSL,acost2)
```

```{r single point}
fullSet <- sampleRegular(ancDatSL, size = 1000000,useGDAL = T)
X <- fullSet
X <- X[complete.cases(X),]

fullSet <- sampleRegular(ancDatSL_cost, size = 1000000,useGDAL = T)
Xcost <- fullSet
Xcost <- Xcost[complete.cases(Xcost),]

##templhs <- c_clhs(x = X, size = 100, i_cost = NULL, iter = 10000)

createRandom <- function(X,n){
  small <- sample(1:nrow(X),size = n, replace = F)
  return(X[small,])
}

createLHS <- function(X,n){
  temp <- c_clhs(X,size = n, i_cost = NULL, iter = 5000)
  small <- as.matrix(temp$sampled_data)
  return(small)
}
createCCLHS <- function(X,n){
  temp <- c_clhs(X,size = n,i_cost = ncol(X), iter = 1000)
  small <- as.matrix(temp$sampled_data)
  return(small)
}

worker.init <- function(){
  Rcpp::sourceCpp("CppLHS.cpp")
}

require(doParallel)
cl <- makePSOCKcluster(detectCores()-2)
clusterCall(cl, worker.init)
registerDoParallel(cl)

collectStats <- function(X,sampleFun,nums,testFun1 = sumKSTest,testFun2 = fillTest, testFun3 = adTest){
  test_res <- foreach(n = nums, .combine = rbind, .noexport = c("CppLHS"), 
                    .packages = c("Rcpp","LaplacesDemon","foreach","goftest"),
                    .export = c("c_clhs")) %dopar% {
                      smallSet <- sampleFun(X,n)
                      res1 <- testFun1(X[,1:6],smallSet)
                      res2 <- testFun2(X[,1:6], smallSet)
                      #res3 <- testFun3(X[,1:6], smallSet)
                      data.frame(Num = n,KS = res1, fill = res2)
                    }
  return(test_res)
}

nums <- round(seq(10, 800, length.out = 20))
nums <- rep(nums, each = 5)
statsRand <- collectStats(X,createRandom,nums)
statsRand$SType <- "Random"
statsLHS <- collectStats(X,createLHS, nums)
statsLHS$SType <- "LHS"
statsCCLHS <- collectStats(Xcost,createCCLHS, nums)
statsCCLHS$SType <- "CCLHS"

statsAll <- rbind(statsRand,statsLHS,statsCCLHS)
statsAll$Num <- as.factor(statsAll$Num)
statsAll$SType <- as.factor(statsAll$SType)

ggplot(statsAll, aes(x = Num, y = KS, fill = SType))+
  geom_boxplot()
ggplot(statsAll, aes(x = Num, y = fill, fill = SType))+
  geom_boxplot()

statsAll <- as.data.table(statsAll)
statsAll[, Norm := (KS-min(KS))/(max(KS)-min(KS))]
statsAll[,Norm := 1-Norm]
ggplot(statsAll, aes(x = Num, y = Norm, fill = SType))+
  geom_boxplot()
```

```{r transects}
ancDatLL_cost <- stack(ancDatLL,acost2)
fullSet <- sampleRegular(ancDatLL, size = 100000,sp = T)
X <- st_as_sf(fullSet)
X <- X[!is.na(X$X25m_DAH_3Class),]
fullSL <- sampleRegular(ancDatSL, size = 1000000,GDAL = T)
fullSL <- fullSL[complete.cases(fullSL),]

fullSet <- sampleRegular(ancDatLL_cost, size = 100000,sp = T)
Xcost <- st_as_sf(fullSet)
Xcost <- Xcost[!is.na(Xcost$X25m_DAH_3Class),]
Xcost <- Xcost[!is.infinite(Xcost$layer),]

createLHS <- function(X,n,ancDat){
  xMat <- as.matrix(st_drop_geometry(X))
  temp <- c_clhs(xMat,size = n,i_cost = NULL,iter = 5000)
  dat <- X[temp$indeces,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tPs <- st_sample(tri, size = 15, type = "regular")
    temp <- suppressWarnings(st_sf(data.frame(id = j, geometry = tPs)) %>%
       st_cast("POINT"))
    temp
    
  }
  temp <- suppressWarnings(raster::extract(ancDat, small))
  temp <- temp[!is.na(temp[1,]),]
  return(temp)
}

createCCLHS <- function(X,n,ancDat){
  xMat <- as.matrix(st_drop_geometry(X))
  temp <- c_clhs(xMat,size = n,i_cost = ncol(xMat),iter = 5000)
  dat <- X[temp$indeces,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tPs <- st_sample(tri, size = 15, type = "regular")
    temp <- suppressWarnings(st_sf(data.frame(id = j, geometry = tPs)) %>%
       st_cast("POINT"))
    temp
    
  }
  temp <- suppressWarnings(raster::extract(ancDat, small))
  temp <- temp[!is.na(temp[1,]),]
  return(temp)
}

createTSP <- function(X,n,ancDat){
  xMat <- as.matrix(st_drop_geometry(X))
  temp <- c_clhs(xMat,size = n,i_cost = ncol(xMat),iter = 5000)
  dat <- X[temp$indeces,]

  pnts <- dat
  
  p2 <- st_as_sf(pnts)
  pnts <- pnts[,1]
  colnames(pnts) <- c("name","geometry")
  st_geometry(pnts) <- "geometry"
  startPnts <- st_as_sf(data.frame(name = "Start",geometry = start_sf))
  pnts <- rbind(pnts, startPnts)
  pnts2 <- as(pnts, "Spatial")
  
  ## create distance matrix between sample points
  test <- costDistance(tr1,pnts2,pnts2)
  dMat2 <- as.matrix(test)
  dMat2 <- dMat2*60
  dMat2[is.infinite(dMat2)] <- 1000
  
  ##penalty based on quality of points
  objVals <- temp[["final_obj"]]
  objVals <- max(objVals) - objVals
  
  maxTime <- 8L ##hours
  ## time per transect
  plotTime <- 45L ##mins
  minPen <- (maxTime*60L)/2L
  maxPen <- (maxTime*60L)*2L
  objVals <- scales::rescale(objVals, to = c(minPen,maxPen))
  objVals <- as.integer(objVals)
  
  ndays <- as.integer(ceiling(n/5)+1)
  indStart <- as.integer(rep(n,ndays))
  ##run vehicle routing problem from python script
  ## GCS is global span cost coefficient
  vrp <- py_mTSP(dat = dMat2,num_days = ndays, start = indStart, end = indStart, 
                 max_cost = maxTime*60L, plot_time = plotTime, penalty =  objVals, arbDepot = F, GSC = 5L)
  result <- vrp[[1]]
  idxs <- as.numeric(unlist(result))
  idxs <- idxs[idxs != n]
  idxs <- idxs+1
  
  dat <- pnts[idxs,]
  small <- foreach(j = 1:nrow(dat),.combine = rbind) %do% {
    tri <- Tri_build(id = j, x = st_coordinates(dat[j,])[1],y = st_coordinates(dat[j,])[2])
    tPs <- st_sample(tri, size = 15, type = "regular")
    temp <- suppressWarnings(st_sf(data.frame(id = j, geometry = tPs)) %>%
       st_cast("POINT"))
    temp
    
  }
  temp <- raster::extract(ancDat, small)
  temp <- temp[!is.na(temp[1,]),]
  return(temp)
}

worker.init <- function(){
  Rcpp::sourceCpp("CppCLHS.cpp")
}

require(doParallel)
cl <- makePSOCKcluster(detectCores()-2)
clusterCall(cl, worker.init)
registerDoParallel(cl)

collectStats <- function(X,sampleFun,nums,testFun1 = sumKSTest,testFun2 = fillTest,ancDat){
  pkgs <- c("Rcpp","LaplacesDemon", "foreach","sf",
          "raster","LearnGeom","dplyr","reticulate","gdistance","scales")
  test_res <- foreach(n = nums, .combine = rbind, .noexport = c("CppLHS"), 
                      .packages = pkgs,
                    .export = c("c_clhs","Tri_build","fullSL","start_sf","tr1")) %dopar% {
                      reticulate::source_python("mTSP.py")
                      smallSet <- sampleFun(X,n,ancDat)
                      res1 <- testFun1(fullSL,smallSet)
                      res2 <- testFun2(fullSL,smallSet)
                      data.frame(Num = n,KS = res1, fillQual = res2)
                    }
  return(test_res)
}

nums <- round(seq(5, 100, length.out = 20))
nums <- rep(nums, each = 5)
statsLHS_trans <- collectStats(X,createLHS,nums,ancDat = ancDatSL)
statsLHS_trans$SType = "LHS"
boxplot(KS ~ Num, data = statsLHS_trans)
boxplot(fillQual ~ Num, data = statsLHS_trans)
statsCCLHS_trans <- collectStats(Xcost,createCCLHS,nums, ancDat = ancDatSL)
boxplot(fillQual ~ Num, data = statsCCLHS_trans)
statsCCLHS_trans$SType <- "CCLHS"
statsTSP_trans <- collectStats(Xcost, createTSP, nums, ancDat = ancDatSL)

etest <- function(full,small){
  dat <- rbind(full,small)
  s <- c(nrow(full),nrow(small))
  temp <- eqdist.e(dat, sizes = s)
}

```

